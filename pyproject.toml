[project]
name = "flame"
dynamic = ["version"]
description = "A minimal training framework for scaling FLA models"
readme = "README.md"
authors = [
    { name = "Songlin Yang", email = "yangsl66@mit.edu" },
    { name = "Yu Zhang", email = "yzhang.cs@outlook.com" },
]
license = { file = "LICENSE" }
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
requires-python = ">=3.10"
dependencies = [
    "flash-linear-attention @ git+https://github.com/fla-org/flash-linear-attention",
    "flash-attn==2.5.8",
    "torch>=2.6.0,<2.7.0",
    "torchvision>=0.21.0,<0.22.0",
    "torchdata",
    "transformers>=4.45.0",
    "triton>=3.0",
    "datasets>=3.3.0",
    "einops",
    "ninja",
    "wandb",
    "tiktoken",
    "tensorboard",
    "omegaconf",
    "Pillow",
    "imageio",
    "numpy",
    "pyarrow>=20.0.0",
    "safetensors>=0.5.3",
    "torchtitan @ git+https://github.com/pytorch/torchtitan.git@0b44d4c",
    "tyro",
    "psutil",
]

[project.optional-dependencies]
dev = ["pytest"]
eval = [
    "lm_eval[ruler,hf] @ git+https://github.com/EleutherAI/lm-evaluation-harness",
]

[project.urls]
Homepage = "https://github.com/fla-org/flame"

[build-system]
requires = ["setuptools>=45", "wheel", "ninja", "torch"]

[tool.isort]
line_length = 127
multi_line_output = 3

[tool.uv.extra-build-dependencies]
flash-attn = ["torch", "numpy", "psutil"]

[tool.uv]
no-build-isolation-package = ["flash-attn"]